{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "This notebook walks through the process of analyzing time series data in the neighborhood of \"events\", in this case the events of interest are specifically windows of time where individuals report experiencing influenza-like illness (ILI). Specifically we are interested in pairing daily features computed via raw data collected from a commercial Fitbit device in order to quantify the impact of ILI on behavior and physiology.\n",
    "\n",
    "\n",
    "**Learning Objectives:**\n",
    "1. Combine reported maximal symptom dates with passively measured daily features in order to construct analysis windows for each individual\n",
    "2. Use time series visualization techniques to better understand individual and population responses to ILI across measurement dimensions\n",
    "3. Use a fixed effects regression framework to estimate the average ILI impact trajectory in the neighborhood of an ILI event\n",
    "4. Construct a rudimentary machine learning pipeline to differentiate between ILI and control windows\n",
    "\n",
    "**Notes**\n",
    "- For this analysis we will use simulation data rather than actual data pulled from individuals. This is to preserve privacy of individuals. The underlying distribution of features is reasonably similar to what we observe empirically using actual ILI event data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies\n",
    "\n",
    "We'll be using some standard data analysis libraries for this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max.rows', 100)\n",
    "pd.set_option('max.columns', 100)\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze | grep -i lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Users/bbradshaw/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in the data\n",
    "\n",
    "For this analysis there are two fundamental data components:\n",
    "1. **User reported events:** This table contains one row per user corresponding to the date where the user reported that their symptoms were at their worst\n",
    "2. **User Fitbit Features**: This table contains multiple rows per user, corresponding to features derived from raw Fitbit data. There are 29 days per user. In econometric parlance, we would call this a *balanced panel*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = pd.read_csv(os.path.join(data_dir, 'user_events.csv'), parse_dates=['event_date'])\n",
    "features = pd.read_csv(os.path.join(data_dir, 'features.csv'), parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doing a quick inspection of the data\n",
    "\n",
    "Let's take a peek at each of our tables to ensure we have an idea of what sort of data we are dealing with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's inspect the events table\n",
    "events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the distribution of reporte ILI event dates\n",
    "events.event_date.hist(density=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that flu season peaked around Februrary. These event dates are simulated and in actuality you wouldn't see such a symmetric \"normal\" distribution for flu incidence since the rate of increase up until peak flue season likely won't mirror the rate of decrease after the peak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.groupby('user_id').size().max(), events.user_id.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, there is one row per user. Next, let's take a look at the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three features we will be using throughout the analysis:\n",
    "1. `steps_sum`: The daily sum of steps walked for a user on a given date\n",
    "2. `sleep_disturbances`: The estimated number of sleep disturbances measured on a given night's sleep\n",
    "3. `resting_heart_rate`: A user's estimated resting heart rate on a given date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aligning user time series to a common distance from event\n",
    "\n",
    "One of the issues we have here is that we need to \"align\" the behavioral and physiological features with the event dates reported by users. The idea is that if we know approximately \"when\" flu events took place, we could then do some investigation of interesting anomolies within the time series surrounding those events.\n",
    "\n",
    "We'll do precisely that! For each user-date, we will generate a \"relative index date\" which is simply the integer valued number of days from the reported peak symptom date (negative values imply dates before the reported peak symptom date, positive values after)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First join each user's event date with features\n",
    "features = features.merge(events, on='user_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have dates and event dates\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['relative_idx'] = (features.date - features.event_date) / pd.Timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect! We now have a `relative_idx` variable that specifies for each user-day observation, how far (in days) that day is from peak symptom severity. The reason we do this is so that we can align the activity data with a cosistent notion of when the event occured across users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary time series analysis: visualization\n",
    "\n",
    "In general, the best approach to analysis is to start with the simplest possible approach that makes sense. Many times, *plotting* data in a reasonable manner is a great way to get an understanding of te underlying dynamics of the problem at hand. We'll do just that.\n",
    "\n",
    "Our approach will be as follows:\n",
    "- For each user create a `relative_idx` column that specifies how far a day is from the peak reporte symptom date (we already did this)\n",
    "- Plot the mean value across all user time series (for each feature) and use the bootstrap to get an estimate of confidence about the mean\n",
    "- Take a look at how feature time series change in the neighborhood of ILI events\n",
    "\n",
    "Let's implement!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Seaborn actually makes this quite easy\n",
    "for f in ['steps_sum', 'sleep_disturbances', 'resting_heart_rate']:\n",
    "    plt.figure(figsize=(20,12))\n",
    "    sns.lineplot(x='relative_idx', y=f, data=features, ci=95, n_boot=10000, color='purple', alpha=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! So there is clearly some signal here. A few observations here:\n",
    "- Average steps decrease in the neighborhood of a flu event\n",
    "- Average sleep disturbances increase in the neighborhood of a flu event\n",
    "- Average resting heart rate increases in the neighborhood of a flu event\n",
    "\n",
    "Note that here we are making observations about the mean, not about individual responses to ILI. It may be useful to plot a random sample of *individual* time series feature trajectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Seaborn actually makes this quite easy\n",
    "for f in ['steps_sum', 'sleep_disturbances', 'resting_heart_rate']:\n",
    "    plt.figure(figsize=(20,12))\n",
    "    sns.lineplot(\n",
    "        x='relative_idx',\n",
    "        y=f,\n",
    "        data=features,\n",
    "        ci=95,\n",
    "        n_boot=10000,\n",
    "        color='purple',\n",
    "        alpha=0.8\n",
    "    )\n",
    "\n",
    "    sns.lineplot(\n",
    "        x='relative_idx',\n",
    "        y=f,\n",
    "        data=features.merge(user_events[['user_id']].sample(frac=0.01, random_state=42), on='user_id'),\n",
    "        color='black',\n",
    "        alpha=0.6,\n",
    "        units='user_id',\n",
    "        estimator=None\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One point the above graphs makes is that even though the average of the feature trajectories shows a clear pattern, individual trajectories are quite noisy. This is something to keep in mind if we attempt to build a *prediction* model that attempts to distinguish windows of time containing a flu event from control windows that do not contain a flu event."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating the impact of ILI events on behavior and physiology: Fixed effects regression\n",
    "\n",
    "While the bootstrap method above is great for a first pass exploration, it isn't a robust analytically framework that allows us to make strong inferential claims. One way we can model how a feature changes in the neighborhood of an ILI event is to use wht econometricians call \"the fixed effects estimator\" or the \"within estimator\" The idea is that since we have multiple measurements per subject, a standard OLS model would be biased since residuals of the model are no longer independent from one another (since blocks of observations are generated from a single individual). We won't go into the details of fixed effects regression modeling (indeed entire classes are taught on the subject). The idea here is that we will model the average value of the feature as a function of distance from peak symtom date, while accounting for unobserved heterogeniety that is fixed at the level of the individual.\n",
    "\n",
    "Luckily there is already a python library that implements the estimation routine for us: `linearmodels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import linearmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
